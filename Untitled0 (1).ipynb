{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK8wz0Rcxwcm",
        "outputId": "42505a70-04ff-4ab5-e5d4-9e02884f3416"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.9/dist-packages (from pdfminer.six) (40.0.2)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from pdfminer.six) (2.0.12)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
            "Installing collected packages: pdfminer.six\n",
            "Successfully installed pdfminer.six-20221105\n"
          ]
        }
      ],
      "source": [
        "pip install pdfminer.six"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pdfminer.high_level import extract_text\n",
        "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
        "from pdfminer.converter import TextConverter\n",
        "from pdfminer.layout import LAParams\n",
        "from pdfminer.pdfpage import PDFPage\n",
        "from io import StringIO\n",
        "import os"
      ],
      "metadata": {
        "id": "lWCws3D0x7CK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "521kGG88x_xg",
        "outputId": "adbb5da0-6fec-4853-bb1e-0d6204a6f7b5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_pdf_to_txt(path):\n",
        "    rsrcmgr = PDFResourceManager()\n",
        "    retstr = StringIO()\n",
        "    codec = 'utf-8'\n",
        "    laparams = LAParams()\n",
        "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
        "    fp = open(path, 'rb')\n",
        "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
        "    password = \"\"\n",
        "    maxpages = 0\n",
        "    caching = True\n",
        "    pagenos=set()\n",
        "\n",
        "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n",
        "        interpreter.process_page(page)\n",
        "\n",
        "    text = retstr.getvalue()\n",
        "\n",
        "    fp.close()\n",
        "    device.close()\n",
        "    retstr.close()\n",
        "    return text\n",
        "\n",
        "directory = '/content/gdrive/MyDrive/RAKE'\n",
        "result = []\n",
        "for filename in os.scandir(directory):\n",
        "    if filename.is_file():\n",
        "        #print(filename.path)\n",
        "        try:\n",
        "          extract = convert_pdf_to_txt(filename.path)\n",
        "          result.append(extract)\n",
        "        except Exception:\n",
        "          print(\"ERROR\"+filename.path)\n",
        "          pass\n",
        "        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeUXYqMdy9h8",
        "outputId": "6392eb8c-b256-4df8-f01d-257633e10ab4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR/content/gdrive/MyDrive/RAKE/10.pdf\n",
            "ERROR/content/gdrive/MyDrive/RAKE/~$NVIVO.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRoPFVuoy-IZ",
        "outputId": "1549d6b5-e3a4-4563-a657-3b1254fa1c5c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import collections\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from string import digits\n",
        "import re\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLE2HsSwIug9",
        "outputId": "ae0862ed-38ac-4491-dc39-9c73018594d0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "punctuations = ['(',')',';',':','[',']',',']\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "\n",
        "#for text in result:\n",
        "#  tokens = word_tokenize(text)\n",
        "# useless keywords\n",
        "useless_keywords = [\"table\", \"crossref\", \"of\", \"pp\", \"pubmed\", \"see\", \"forinstance\" \"huang\", \"etal\", \"huangetal\", \"wu\", \"avalentin\", \"jhspangenbergenvironimpactassessmentrev\", \"ment\", \"etc\", \"ie\", \"schu\", \"infig\", \"hinterbergerf\", \"et\",\"al\"]\n",
        "wordcount = {}\n",
        "text=\"\"\n",
        "for r in result:\n",
        "  text+=r\n",
        "tokens = word_tokenize(text)\n",
        "keywords = [word for word in tokens if not word in stop_words and  not word in punctuations]\n",
        "\n",
        "for word in keywords:\n",
        "\tword = word.lower()\n",
        "\tword = re.sub('[^a-zA-Z0-9\\n\\.]', ' ', word)\n",
        "\tword = ''.join([i for i in word if not i.isdigit()])\n",
        "\tword = word.replace(\".\",\"\")\n",
        "\tword = word.replace(\",\",\"\")\n",
        "\tword = word.replace(\":\",\"\")\n",
        "\tword = word.replace(\"\\\"\",\"\")\n",
        "\tword = word.replace(\"!\",\"\")\n",
        "\tword = word.replace(\"*\",\"\")\n",
        "\tword = word.replace(\" \",\"\")\n",
        "\tif word != '' and len(word) > 1 and word not in useless_keywords:\n",
        "\t\tif word not in wordcount:\n",
        "\t\t\twordcount[word] = 1\n",
        "\t\telse:\n",
        "\t\t\twordcount[word] += 1\n",
        "\n",
        "# Print most common word\n",
        "n_print = int(input(\"How many most common words to print: \"))\n",
        "print(\"\\nOK. The {} most common words are as follows\\n\".format(n_print))\n",
        "word_counter = collections.Counter(wordcount)\n",
        "for word, count in word_counter.most_common(n_print):\n",
        "    print(word, \": \", count)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25sFPeDbMp3n",
        "outputId": "f129509b-7820-456b-9cf8-6e54cde6ff94"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How many most common words to print: 50\n",
            "\n",
            "OK. The 50 most common words are as follows\n",
            "\n",
            "housing :  12697\n",
            "the :  8945\n",
            "in :  3290\n",
            "energy :  3232\n",
            "social :  2793\n",
            "building :  2642\n",
            "urban :  2636\n",
            "criteria :  2556\n",
            "sustainable :  2549\n",
            "development :  2529\n",
            "this :  2509\n",
            "project :  2470\n",
            "study :  2302\n",
            "public :  2275\n",
            "research :  2265\n",
            "also :  2252\n",
            "affordable :  2240\n",
            "cid :  2167\n",
            "policy :  2160\n",
            "sustainability :  2021\n",
            "land :  2018\n",
            "construction :  2000\n",
            "new :  1982\n",
            "data :  1980\n",
            "analysis :  1972\n",
            "projects :  1900\n",
            "factors :  1891\n",
            "city :  1788\n",
            "management :  1755\n",
            "success :  1686\n",
            "household :  1686\n",
            "households :  1676\n",
            "market :  1646\n",
            "local :  1640\n",
            "income :  1621\n",
            "affordability :  1562\n",
            "one :  1548\n",
            "cost :  1533\n",
            "use :  1510\n",
            "environmental :  1463\n",
            "government :  1440\n",
            "planning :  1434\n",
            "economic :  1413\n",
            "however :  1364\n",
            "case :  1356\n",
            "quality :  1350\n",
            "used :  1333\n",
            "house :  1328\n",
            "studies :  1323\n",
            "private :  1292\n"
          ]
        }
      ]
    }
  ]
}